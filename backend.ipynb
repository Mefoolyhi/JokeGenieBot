{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mefoolyhi/JokeGenieBot/blob/main/backend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxELmob9QQ-L",
        "outputId": "203374a6-dc09-48d4-d382-8696694e0ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.10/dist-packages (13.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot) (2024.2.2)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot) (6.3.3)\n",
            "Requirement already satisfied: APScheduler==3.6.3 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot) (3.6.3)\n",
            "Requirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot) (2023.4)\n",
            "Requirement already satisfied: cachetools==4.2.2 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot) (4.2.2)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.16.0)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-telegram-bot requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-telegram-bot==13.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6eKqZ4BQUf9",
        "outputId": "dfb9e3a6-cad1-41a7-ddbf-0e2ecd8c8ad5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-telegram-bot==13.7\n",
            "  Downloading python_telegram_bot-13.7-py3-none-any.whl (490 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.1/490.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.7) (2024.2.2)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.7) (6.3.3)\n",
            "Collecting APScheduler==3.6.3 (from python-telegram-bot==13.7)\n",
            "  Downloading APScheduler-3.6.3-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.7) (2023.4)\n",
            "Collecting cachetools==4.2.2 (from python-telegram-bot==13.7)\n",
            "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.7) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.7) (1.16.0)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.7) (5.2)\n",
            "Installing collected packages: cachetools, APScheduler, python-telegram-bot\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.3\n",
            "    Uninstalling cachetools-5.3.3:\n",
            "      Successfully uninstalled cachetools-5.3.3\n",
            "Successfully installed APScheduler-3.6.3 cachetools-4.2.2 python-telegram-bot-13.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "IImUAUN82TeK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc795754-7924-4d94-f64b-75afc6d51fbe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.41.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCXr8tMj2m_h",
        "outputId": "38071da7-b84f-4262-cd69-b39750eb7576"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "import os\n",
        "from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\n",
        "from telegram.ext import Updater, CommandHandler, CallbackQueryHandler, CallbackContext\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import NLTKWordTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Токен вашего бота\n",
        "TOKEN = '7065562212:AAHiu-AYQ9ggAz9f0jlJoGNu_vM4FQPzDpQ'\n",
        "\n",
        "# Файл с анекдотами\n",
        "JOKES_FILE = 'total_data_jokes_512.csv'\n",
        "# Файл для хранения истории оценок пользователей\n",
        "HISTORY_FILE = 'user_favorites.csv'\n",
        "\n",
        "# Словари для хранения понравившихся, не понравившихся и просмотренных анекдотов для каждого пользователя\n",
        "user_favorites = {}\n",
        "user_dislikes = {}\n",
        "user_viewed = {}\n",
        "index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
        "encoder = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "# Функция для загрузки анекдотов из CSV-файла\n",
        "def load_jokes(filename):\n",
        "    total_data = pd.read_csv('total_data_jokes_512.csv', encoding = \"utf-8\")\n",
        "    jokes = total_data['joke']\n",
        "    encoded_data = encoder.encode(jokes) # это будет работать минут 10, это нормально\n",
        "    index.add_with_ids(encoded_data, np.arange(len(jokes)))\n",
        "    return jokes\n",
        "\n",
        "# Загрузка анекдотов при старте\n",
        "jokes = load_jokes(JOKES_FILE)\n",
        "\n",
        "# Функция для загрузки истории оценок пользователей из CSV-файла\n",
        "def load_user_favorites(filename):\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, newline='', encoding='utf-8') as csvfile:\n",
        "            reader = csv.reader(csvfile)\n",
        "            next(reader)  # Пропустить заголовок\n",
        "            for row in reader:\n",
        "                if row:  # Проверка, что строка не пустая\n",
        "                    try:\n",
        "                        user_id = int(row[0])\n",
        "                        likes = row[1].split('|') if row[1] else []\n",
        "                        dislikes = row[2].split('|') if row[2] else []\n",
        "                        viewed = row[3].split('|') if row[3] else []\n",
        "                        user_favorites[user_id] = likes\n",
        "                        user_dislikes[user_id] = dislikes\n",
        "                        user_viewed[user_id] = viewed\n",
        "                    except ValueError:\n",
        "                        print(f\"Ошибка преобразования user_id в целое число: {row[0]}\")\n",
        "    else:\n",
        "        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            writer.writerow(['user_id', 'favorites', 'dislikes', 'viewed'])\n",
        "\n",
        "# Сохранение истории оценок пользователей в CSV-файл\n",
        "def save_user_favorites(filename):\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['user_id', 'favorites', 'dislikes', 'viewed'])\n",
        "        for user_id in user_favorites:\n",
        "            favorites = '|'.join(user_favorites.get(user_id, []))\n",
        "            dislikes = '|'.join(user_dislikes.get(user_id, []))\n",
        "            viewed = '|'.join(user_viewed.get(user_id, []))\n",
        "            writer.writerow([user_id, favorites, dislikes, viewed])\n",
        "\n",
        "# Загрузка истории оценок при старте\n",
        "load_user_favorites(HISTORY_FILE)\n",
        "\n",
        "def start(update: Update, context: CallbackContext) -> None:\n",
        "    print(\"Received start command!\")  # Выводим сообщение о получении команды \"start\"\n",
        "    user_id = update.message.from_user.id\n",
        "    if user_id not in user_favorites:\n",
        "        user_favorites[user_id] = []\n",
        "    if user_id not in user_dislikes:\n",
        "        user_dislikes[user_id] = []\n",
        "    if user_id not in user_viewed:\n",
        "        user_viewed[user_id] = []\n",
        "\n",
        "    # Инициализация списка просмотренных анекдотов\n",
        "    context.user_data['viewed_jokes'] = []\n",
        "\n",
        "    keyboard = [\n",
        "        [InlineKeyboardButton(\"Показать анекдот\", callback_data='show_joke')],\n",
        "        [InlineKeyboardButton(\"Понравившиеся анекдоты\", callback_data='show_favorites')]\n",
        "    ]\n",
        "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "    update.message.reply_text('Привет! Нажми кнопку ниже, чтобы получить анекдот или посмотреть понравившиеся анекдоты.', reply_markup=reply_markup)\n",
        "\n",
        "def show_joke(update: Update, context: CallbackContext) -> None:\n",
        "    query = update.callback_query\n",
        "    query.answer()\n",
        "    user_id = query.from_user.id\n",
        "\n",
        "    if user_id not in user_favorites:\n",
        "        user_favorites[user_id] = []\n",
        "    if user_id not in user_dislikes:\n",
        "        user_dislikes[user_id] = []\n",
        "    if user_id not in user_viewed:\n",
        "        user_viewed[user_id] = []\n",
        "\n",
        "    # Инициализируем 'viewed_jokes', если он еще не был создан\n",
        "    if 'viewed_jokes' not in context.user_data:\n",
        "        context.user_data['viewed_jokes'] = []\n",
        "\n",
        "    viewed_jokes = context.user_data['viewed_jokes']\n",
        "\n",
        "    last_liked = user_favorites[user_id][-5:]\n",
        "\n",
        "\n",
        "    if last_liked:\n",
        "        query_vector = encoder.encode(last_liked)\n",
        "        top_k = index.search(query_vector, 10)\n",
        "        top_jokes = []\n",
        "        for _id in top_k[1][0]:\n",
        "            joke = jokes[_id]\n",
        "            if joke not in viewed_jokes:\n",
        "                top_jokes.append(joke)\n",
        "\n",
        "        unliked = user_dislikes[user_id]\n",
        "        if unliked and top_k:\n",
        "            tokenizer = NLTKWordTokenizer()\n",
        "            unliked_tok = [tokenizer.tokenize(x.lower()) for x in unliked]\n",
        "            top_jokes_tok = [tokenizer.tokenize(x.lower()) for x in top_jokes]\n",
        "\n",
        "            lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "            russian_stopwords = stopwords.words(\"russian\")\n",
        "            unliked_tokens = []\n",
        "            for row in unliked_tok:\n",
        "                row_tokens = []\n",
        "                for token in row:\n",
        "                    if token not in russian_stopwords and token not in punctuation:\n",
        "                        row_tokens.append(lemmatizer.lemmatize(token))\n",
        "                unliked_tokens.append(' '.join(row_tokens))\n",
        "\n",
        "            top_tokens = []\n",
        "            for row in top_jokes_tok:\n",
        "                row_tokens = []\n",
        "                for token in row:\n",
        "                    if token not in russian_stopwords and token not in punctuation:\n",
        "                        row_tokens.append(lemmatizer.lemmatize(token))\n",
        "                top_tokens.append(row_tokens)\n",
        "\n",
        "\n",
        "            tf_idf = TfidfVectorizer()\n",
        "            unliked_array = tf_idf.fit_transform(unliked_tokens)\n",
        "            threshold = 0.2 # тут его возможно надо будет поднять\n",
        "            important_words = [word for word, score in zip(tf_idf.get_feature_names_out(), unliked_array.toarray()[0]) if score >= threshold]\n",
        "            important_set = set(important_words)\n",
        "            counts = []\n",
        "            for joke in top_tokens:\n",
        "                local_count = 0\n",
        "                for token in joke:\n",
        "                    if token in important_words:\n",
        "                        local_count += 1\n",
        "                counts.append(local_count)\n",
        "\n",
        "            final_joke = top_jokes[np.argmin(counts)]\n",
        "        else:\n",
        "            final_joke = random.choice(top_jokes)\n",
        "    else:\n",
        "        available_jokes = [j for j in jokes if j not in viewed_jokes]\n",
        "\n",
        "        if not available_jokes:\n",
        "            query.message.reply_text(\"Все анекдоты уже показаны!\")\n",
        "            return\n",
        "\n",
        "        final_joke = random.choice(available_jokes)\n",
        "\n",
        "\n",
        "    context.user_data['current_joke'] = final_joke\n",
        "    context.user_data['viewed_jokes'].append(final_joke)\n",
        "    user_viewed[user_id].append(final_joke)\n",
        "\n",
        "    # Сохранение истории оценок\n",
        "    save_user_favorites(HISTORY_FILE)\n",
        "\n",
        "    keyboard = [\n",
        "        [InlineKeyboardButton(\"👍 Понравился\", callback_data='like'),\n",
        "         InlineKeyboardButton(\"👎 Не понравился\", callback_data='dislike')],\n",
        "        [InlineKeyboardButton(\"Еще\", callback_data='show_joke')],\n",
        "        [InlineKeyboardButton(\"Понравившиеся анекдоты\", callback_data='show_favorites')]\n",
        "    ]\n",
        "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "\n",
        "    # Отправляем анекдот\n",
        "    query.message.reply_text(text=final_joke, reply_markup=reply_markup)\n",
        "\n",
        "def show_favorites(update: Update, context: CallbackContext) -> None:\n",
        "    query = update.callback_query\n",
        "    query.answer()\n",
        "    user_id = query.from_user.id\n",
        "\n",
        "    if user_id not in user_favorites or not user_favorites[user_id]:\n",
        "        query.edit_message_text(text=\"У вас нет понравившихся анекдотов.\")\n",
        "        # тут не хватает кнопок\n",
        "        return\n",
        "\n",
        "    favorites = user_favorites[user_id]\n",
        "    favorites_text = \"\\n\\n\".join(favorites)\n",
        "\n",
        "    # Показываем список понравившихся анекдотов\n",
        "    query.edit_message_text(text=f\"Ваши понравившиеся анекдоты:\\n\\n{favorites_text}\")\n",
        "\n",
        "    # Добавляем кнопку \"Показать анекдот\"\n",
        "    keyboard = [\n",
        "        [InlineKeyboardButton(\"Показать анекдот\", callback_data='show_joke')]\n",
        "    ]\n",
        "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "    query.message.reply_text('Нажми кнопку ниже, чтобы получить анекдот.', reply_markup=reply_markup)\n",
        "\n",
        "def handle_feedback(update: Update, context: CallbackContext) -> None:\n",
        "    query = update.callback_query\n",
        "    query.answer()\n",
        "    user_id = query.from_user.id\n",
        "\n",
        "    if user_id not in user_favorites:\n",
        "        user_favorites[user_id] = []\n",
        "    if user_id not in user_dislikes:\n",
        "        user_dislikes[user_id] = []\n",
        "    if user_id not in user_viewed:\n",
        "        user_viewed[user_id] = []\n",
        "\n",
        "    feedback = query.data\n",
        "    current_joke = context.user_data.get('current_joke', None)\n",
        "\n",
        "    if current_joke:\n",
        "        if feedback == 'like':\n",
        "            user_favorites[user_id].append(current_joke)\n",
        "        elif feedback == 'dislike':\n",
        "            user_dislikes[user_id].append(current_joke)\n",
        "\n",
        "        # Сохранение истории оценок\n",
        "        save_user_favorites(HISTORY_FILE)\n",
        "\n",
        "    # Показываем благодарность за отзыв\n",
        "    query.message.reply_text(\"Спасибо за отзыв!\")\n",
        "\n",
        "    # Добавляем кнопку \"Показать анекдот\"\n",
        "    keyboard = [\n",
        "        [InlineKeyboardButton(\"Показать анекдот\", callback_data='show_joke')],\n",
        "        [InlineKeyboardButton(\"Понравившиеся анекдоты\", callback_data='show_favorites')]\n",
        "    ]\n",
        "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "    query.message.reply_text('Нажми кнопку ниже, чтобы получить анекдот.', reply_markup=reply_markup)\n",
        "\n",
        "def main() -> None:\n",
        "    updater = Updater(TOKEN)\n",
        "    dispatcher = updater.dispatcher\n",
        "\n",
        "    dispatcher.add_handler(CommandHandler(\"start\", start))\n",
        "    dispatcher.add_handler(CallbackQueryHandler(show_joke, pattern='show_joke'))\n",
        "    dispatcher.add_handler(CallbackQueryHandler(handle_feedback, pattern='like|dislike'))\n",
        "    dispatcher.add_handler(CallbackQueryHandler(show_favorites, pattern='show_favorites'))\n",
        "\n",
        "    updater.start_polling()\n",
        "    updater.idle()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "6by0WMhknJhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b2633f-fa60-4508-f3ca-1d437e4ed2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}